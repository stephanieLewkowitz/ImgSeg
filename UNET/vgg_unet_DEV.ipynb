{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqTwHdYIuo-M"
   },
   "outputs": [],
   "source": [
    "#https://github.com/divamgupta/image-segmentation-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JioP_wUKyEh-"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kK6xKnjXzM-R"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SWlNqIZoVQl5"
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BKHsMvWZuqIM"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# from .data_utils.data_loader import image_segmentation_generator, \\\n",
    "#     verify_segmentation_dataset\n",
    "import six\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2hN568Z1xTqf"
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "# from .config import IMAGE_ORDERING\n",
    "# from .model_utils import get_segmentation_model\n",
    "# from .vgg16 import get_vgg_encoder\n",
    "# from .mobilenet import get_mobilenet_encoder\n",
    "# from .basic_models import vanilla_encoder\n",
    "# from .resnet50 import get_resnet50_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Zk_XzP-cxh-B"
   },
   "outputs": [],
   "source": [
    "IMAGE_ORDERING ='channels_last' # 'channels_last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sF1jNAPpxVny"
   },
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "\n",
    "\n",
    "# def unet_mini(n_classes, input_height=360, input_width=480, channels=3):\n",
    "\n",
    "#     if IMAGE_ORDERING == 'channels_first':\n",
    "#         img_input = Input(shape=(channels, input_height, input_width))\n",
    "#     elif IMAGE_ORDERING == 'channels_last':\n",
    "#         img_input = Input(shape=(input_height, input_width, channels))\n",
    "\n",
    "#     conv1 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(img_input)\n",
    "#     conv1 = Dropout(0.2)(conv1)\n",
    "#     conv1 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(conv1)\n",
    "#     pool1 = MaxPooling2D((2, 2), data_format=IMAGE_ORDERING)(conv1)\n",
    "\n",
    "#     conv2 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(pool1)\n",
    "#     conv2 = Dropout(0.2)(conv2)\n",
    "#     conv2 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(conv2)\n",
    "#     pool2 = MaxPooling2D((2, 2), data_format=IMAGE_ORDERING)(conv2)\n",
    "\n",
    "#     conv3 = Conv2D(128, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(pool2)\n",
    "#     conv3 = Dropout(0.2)(conv3)\n",
    "#     conv3 = Conv2D(128, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(conv3)\n",
    "\n",
    "#     up1 = concatenate([UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(\n",
    "#         conv3), conv2], axis=MERGE_AXIS)\n",
    "#     conv4 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(up1)\n",
    "#     conv4 = Dropout(0.2)(conv4)\n",
    "#     conv4 = Conv2D(64, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(conv4)\n",
    "\n",
    "#     up2 = concatenate([UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(\n",
    "#         conv4), conv1], axis=MERGE_AXIS)\n",
    "#     conv5 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same')(up2)\n",
    "#     conv5 = Dropout(0.2)(conv5)\n",
    "#     conv5 = Conv2D(32, (3, 3), data_format=IMAGE_ORDERING,\n",
    "#                    activation='relu', padding='same' , name=\"seg_feats\")(conv5)\n",
    "\n",
    "#     o = Conv2D(n_classes, (1, 1), data_format=IMAGE_ORDERING,\n",
    "#                padding='same')(conv5)\n",
    "\n",
    "#     model = get_segmentation_model(img_input, o)\n",
    "#     model.model_name = \"unet_mini\"\n",
    "#     return model\n",
    "\n",
    "\n",
    "def _unet(n_classes, encoder, l1_skip_conn=True, input_height=416,\n",
    "          input_width=608, channels=3):\n",
    "\n",
    "    img_input, levels = encoder(\n",
    "        input_height=input_height, input_width=input_width, channels=channels)\n",
    "    [f1, f2, f3, f4, f5] = levels\n",
    "\n",
    "    o = f4\n",
    "\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(512, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f3], axis=MERGE_AXIS))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(256, (3, 3), padding='valid', activation='relu' , data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f2], axis=MERGE_AXIS))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(128, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "\n",
    "    if l1_skip_conn:\n",
    "        o = (concatenate([o, f1], axis=MERGE_AXIS))\n",
    "\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(64, (3, 3), padding='valid', activation='relu', data_format=IMAGE_ORDERING, name=\"seg_feats\"))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same',\n",
    "               data_format=IMAGE_ORDERING)(o)\n",
    "\n",
    "    model = get_segmentation_model(img_input, o)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# def unet(n_classes, input_height=416, input_width=608, encoder_level=3, channels=3):\n",
    "\n",
    "#     model = _unet(n_classes, vanilla_encoder,\n",
    "#                   input_height=input_height, input_width=input_width, channels=channels)\n",
    "#     model.model_name = \"unet\"\n",
    "#     return model\n",
    "\n",
    "\n",
    "def vgg_unet(n_classes, input_height=416, input_width=608, encoder_level=3, channels=3):\n",
    "\n",
    "    model = _unet(n_classes, get_vgg_encoder,\n",
    "                  input_height=input_height, input_width=input_width, channels=channels)\n",
    "    model.model_name = \"vgg_unet\"\n",
    "    return model\n",
    "\n",
    "\n",
    "# def resnet50_unet(n_classes, input_height=416, input_width=608,\n",
    "#                   encoder_level=3, channels=3):\n",
    "\n",
    "#     model = _unet(n_classes, get_resnet50_encoder,\n",
    "#                   input_height=input_height, input_width=input_width, channels=channels)\n",
    "#     model.model_name = \"resnet50_unet\"\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def mobilenet_unet(n_classes, input_height=224, input_width=224,\n",
    "#                    encoder_level=3, channels=3):\n",
    "\n",
    "#     model = _unet(n_classes, get_mobilenet_encoder,\n",
    "#                   input_height=input_height, input_width=input_width, channels=channels)\n",
    "#     model.model_name = \"mobilenet_unet\"\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x6wgj89j9acu"
   },
   "outputs": [],
   "source": [
    "class DataLoaderError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JV5TwN9NwBSk"
   },
   "outputs": [],
   "source": [
    "def verify_segmentation_dataset(images_path, segs_path,\n",
    "                                n_classes, show_all_errors=False):\n",
    "    try:\n",
    "        img_seg_pairs = get_pairs_from_paths(images_path, segs_path)\n",
    "        if not len(img_seg_pairs):\n",
    "            print(\"Couldn't load any data from images_path: \"\n",
    "                  \"{0} and segmentations path: {1}\"\n",
    "                  .format(images_path, segs_path))\n",
    "            return False\n",
    "\n",
    "        return_value = True\n",
    "        for im_fn, seg_fn in tqdm(img_seg_pairs):\n",
    "            img = cv2.imread(im_fn)\n",
    "            seg = cv2.imread(seg_fn)\n",
    "            # Check dimensions match\n",
    "            if not img.shape == seg.shape:\n",
    "                return_value = False\n",
    "                print(\"The size of image {0} and its segmentation {1} \"\n",
    "                      \"doesn't match (possibly the files are corrupt).\"\n",
    "                      .format(im_fn, seg_fn))\n",
    "                if not show_all_errors:\n",
    "                    break\n",
    "            else:\n",
    "                max_pixel_value = np.max(seg[:, :, 0])\n",
    "                if max_pixel_value >= n_classes:\n",
    "                    return_value = False\n",
    "                    print(\"The pixel values of the segmentation image {0} \"\n",
    "                          \"violating range [0, {1}]. \"\n",
    "                          \"Found maximum pixel value {2}\"\n",
    "                          .format(seg_fn, str(n_classes - 1), max_pixel_value))\n",
    "                    if not show_all_errors:\n",
    "                        break\n",
    "        if return_value:\n",
    "            print(\"Dataset verified! \")\n",
    "        else:\n",
    "            print(\"Dataset not verified!\")\n",
    "        return return_value\n",
    "    except DataLoaderError as e:\n",
    "        print(\"Found error during data loading\\n{0}\".format(str(e)))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uOcL2QqM8bSk"
   },
   "outputs": [],
   "source": [
    "def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False, other_inputs_paths=None):\n",
    "    \"\"\" Find all the images from the images_path directory and\n",
    "        the segmentation images from the segs_path directory\n",
    "        while checking integrity of data \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    image_files = []\n",
    "    segmentation_files = {}\n",
    "\n",
    "    for dir_entry in os.listdir(images_path):\n",
    "        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n",
    "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
    "            file_name, file_extension = os.path.splitext(dir_entry)\n",
    "            image_files.append((file_name, file_extension,\n",
    "                                os.path.join(images_path, dir_entry)))\n",
    "\n",
    "    if other_inputs_paths is not None:\n",
    "        other_inputs_files = []\n",
    "\n",
    "        for i, other_inputs_path in enumerate(other_inputs_paths):\n",
    "            temp = []\n",
    "\n",
    "            for y, dir_entry in enumerate(os.listdir(other_inputs_path)):\n",
    "                if os.path.isfile(os.path.join(other_inputs_path, dir_entry)) and \\\n",
    "                        os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
    "                    file_name, file_extension = os.path.splitext(dir_entry)\n",
    "\n",
    "                    temp.append((file_name, file_extension,\n",
    "                                 os.path.join(other_inputs_path, dir_entry)))\n",
    "\n",
    "            other_inputs_files.append(temp)\n",
    "\n",
    "    for dir_entry in os.listdir(segs_path):\n",
    "        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n",
    "           os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n",
    "            file_name, file_extension = os.path.splitext(dir_entry)\n",
    "            full_dir_entry = os.path.join(segs_path, dir_entry)\n",
    "            if file_name in segmentation_files:\n",
    "                raise DataLoaderError(\"Segmentation file with filename {0}\"\n",
    "                                      \" already exists and is ambiguous to\"\n",
    "                                      \" resolve with path {1}.\"\n",
    "                                      \" Please remove or rename the latter.\"\n",
    "                                      .format(file_name, full_dir_entry))\n",
    "\n",
    "            segmentation_files[file_name] = (file_extension, full_dir_entry)\n",
    "\n",
    "    return_value = []\n",
    "    # Match the images and segmentations\n",
    "    for image_file, _, image_full_path in image_files:\n",
    "        if image_file in segmentation_files:\n",
    "            if other_inputs_paths is not None:\n",
    "                other_inputs = []\n",
    "                for file_paths in other_inputs_files:\n",
    "                    success = False\n",
    "\n",
    "                    for (other_file, _, other_full_path) in file_paths:\n",
    "                        if image_file == other_file:\n",
    "                            other_inputs.append(other_full_path)\n",
    "                            success = True\n",
    "                            break\n",
    "\n",
    "                    if not success:\n",
    "                        raise ValueError(\"There was no matching other input to\", image_file, \"in directory\")\n",
    "\n",
    "                return_value.append((image_full_path,\n",
    "                                     segmentation_files[image_file][1], other_inputs))\n",
    "            else:\n",
    "                return_value.append((image_full_path,\n",
    "                                     segmentation_files[image_file][1]))\n",
    "        elif ignore_non_matching:\n",
    "            continue\n",
    "        else:\n",
    "            # Error out\n",
    "            raise DataLoaderError(\"No corresponding segmentation \"\n",
    "                                  \"found for image {0}.\"\n",
    "                                  .format(image_full_path))\n",
    "\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-2JVVCXUv4YM"
   },
   "outputs": [],
   "source": [
    "def image_segmentation_generator(images_path, segs_path, batch_size,\n",
    "                                 n_classes, input_height, input_width,\n",
    "                                 output_height, output_width,\n",
    "                                 do_augment=False,\n",
    "                                 augmentation_name=\"aug_all\",\n",
    "                                 custom_augmentation=None,\n",
    "                                 other_inputs_paths=None, preprocessing=None,\n",
    "                                 read_image_type=cv2.IMREAD_COLOR , ignore_segs=False ):\n",
    "    \n",
    "\n",
    "    if not ignore_segs:\n",
    "        img_seg_pairs = get_pairs_from_paths(images_path, segs_path, other_inputs_paths=other_inputs_paths)\n",
    "        random.shuffle(img_seg_pairs)\n",
    "        zipped = itertools.cycle(img_seg_pairs)\n",
    "    else:\n",
    "        img_list = get_image_list_from_path( images_path )\n",
    "        random.shuffle( img_list )\n",
    "        img_list_gen = itertools.cycle( img_list )\n",
    "\n",
    "\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range(batch_size):\n",
    "            if other_inputs_paths is None:\n",
    "\n",
    "                if ignore_segs:\n",
    "                    im = next( img_list_gen )\n",
    "                    seg = None \n",
    "                else:\n",
    "                    im, seg = next(zipped)\n",
    "                    seg = cv2.imread(seg, 1)\n",
    "\n",
    "                im = cv2.imread(im, read_image_type)\n",
    "                \n",
    "\n",
    "                if do_augment:\n",
    "\n",
    "                    assert ignore_segs == False , \"Not supported yet\"\n",
    "\n",
    "                    if custom_augmentation is None:\n",
    "                        im, seg[:, :, 0] = augment_seg(im, seg[:, :, 0],\n",
    "                                                       augmentation_name)\n",
    "                    else:\n",
    "                        im, seg[:, :, 0] = custom_augment_seg(im, seg[:, :, 0],\n",
    "                                                              custom_augmentation)\n",
    "\n",
    "                if preprocessing is not None:\n",
    "                    im = preprocessing(im)\n",
    "\n",
    "                X.append(get_image_array(im, input_width,\n",
    "                                         input_height, ordering=IMAGE_ORDERING))\n",
    "            else:\n",
    "\n",
    "                assert ignore_segs == False , \"Not supported yet\"\n",
    "\n",
    "                im, seg, others = next(zipped)\n",
    "\n",
    "                im = cv2.imread(im, read_image_type)\n",
    "                seg = cv2.imread(seg, 1)\n",
    "\n",
    "                oth = []\n",
    "                for f in others:\n",
    "                    oth.append(cv2.imread(f, read_image_type))\n",
    "\n",
    "                if do_augment:\n",
    "                    if custom_augmentation is None:\n",
    "                        ims, seg[:, :, 0] = augment_seg(im, seg[:, :, 0],\n",
    "                                                        augmentation_name, other_imgs=oth)\n",
    "                    else:\n",
    "                        ims, seg[:, :, 0] = custom_augment_seg(im, seg[:, :, 0],\n",
    "                                                               custom_augmentation, other_imgs=oth)\n",
    "                else:\n",
    "                    ims = [im]\n",
    "                    ims.extend(oth)\n",
    "\n",
    "                oth = []\n",
    "                for i, image in enumerate(ims):\n",
    "                    oth_im = get_image_array(image, input_width,\n",
    "                                             input_height, ordering=IMAGE_ORDERING)\n",
    "\n",
    "                    if preprocessing is not None:\n",
    "                        if isinstance(preprocessing, Sequence):\n",
    "                            oth_im = preprocessing[i](oth_im)\n",
    "                        else:\n",
    "                            oth_im = preprocessing(oth_im)\n",
    "\n",
    "                    oth.append(oth_im)\n",
    "\n",
    "                X.append(oth)\n",
    "\n",
    "            if not ignore_segs:\n",
    "                Y.append(get_segmentation_array(\n",
    "                    seg, n_classes, output_width, output_height))\n",
    "\n",
    "        if ignore_segs:\n",
    "            yield np.array(X)\n",
    "        else:\n",
    "            yield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_BelJpHGWFQz"
   },
   "outputs": [],
   "source": [
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, read_image_type)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\":\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.atleast_3d(img)\n",
    "\n",
    "        means = [103.939, 116.779, 123.68]\n",
    "\n",
    "        for i in range(min(img.shape[2], len(means))):\n",
    "            img[:, :, i] -= means[i]\n",
    "\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2J4FAgBAWGQJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_segmentation_array(image_input, nClasses,\n",
    "                           width, height, no_reshape=False, read_image_type=1):\n",
    "    \"\"\" Load segmentation array from input \"\"\"\n",
    "\n",
    "    seg_labels = np.zeros((height, width, nClasses))\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_segmentation_array: \"\n",
    "                                  \"path {0} doesn't exist\".format(image_input))\n",
    "        img = cv2.imread(image_input, read_image_type)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_segmentation_array: \"\n",
    "                              \"Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    img = img[:, :, 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[:, :, c] = (img == c).astype(int)\n",
    "\n",
    "    if not no_reshape:\n",
    "        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n",
    "\n",
    "    return seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RDpNg1JPvf71"
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_latest_checkpoint(checkpoints_path, fail_safe=True):\n",
    "\n",
    "    # This is legacy code, there should always be a \"checkpoint\" file in your directory\n",
    "\n",
    "    def get_epoch_number_from_path(path):\n",
    "        return path.replace(checkpoints_path, \"\").strip(\".\")\n",
    "\n",
    "    # Get all matching files\n",
    "    all_checkpoint_files = glob.glob(checkpoints_path + \".*\")\n",
    "    if len(all_checkpoint_files) == 0:\n",
    "        all_checkpoint_files = glob.glob(checkpoints_path + \"*.*\")\n",
    "    all_checkpoint_files = [ff.replace(\".index\", \"\") for ff in\n",
    "                            all_checkpoint_files]  # to make it work for newer versions of keras\n",
    "    # Filter out entries where the epoc_number part is pure number\n",
    "    all_checkpoint_files = list(filter(lambda f: get_epoch_number_from_path(f)\n",
    "                                       .isdigit(), all_checkpoint_files))\n",
    "    if not len(all_checkpoint_files):\n",
    "        # The glob list is empty, don't have a checkpoints_path\n",
    "        if not fail_safe:\n",
    "            raise ValueError(\"Checkpoint path {0} invalid\"\n",
    "                             .format(checkpoints_path))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Find the checkpoint file with the maximum epoch\n",
    "    latest_epoch_checkpoint = max(all_checkpoint_files,\n",
    "                                  key=lambda f:\n",
    "                                  int(get_epoch_number_from_path(f)))\n",
    "\n",
    "    return latest_epoch_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3MYz1a-6wHhO"
   },
   "outputs": [],
   "source": [
    "def masked_categorical_crossentropy(gt, pr):\n",
    "    from keras.losses import categorical_crossentropy\n",
    "    mask = 1 - gt[:, :, 0]\n",
    "    return categorical_crossentropy(gt, pr) * mask\n",
    "\n",
    "\n",
    "class CheckpointsCallback(Callback):\n",
    "    def __init__(self, checkpoints_path):\n",
    "        self.checkpoints_path = checkpoints_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.checkpoints_path is not None:\n",
    "            self.model.save_weights(self.checkpoints_path + \".\" + str(epoch))\n",
    "            print(\"saved \", self.checkpoints_path + \".\" + str(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t8CYhIckwJzz"
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_images,\n",
    "          train_annotations,\n",
    "          input_height=None,\n",
    "          input_width=None,\n",
    "          n_classes=None,\n",
    "          verify_dataset=False, #True\n",
    "          checkpoints_path=None,\n",
    "          epochs=5,\n",
    "          batch_size=2,\n",
    "          validate=False,\n",
    "          val_images=None,\n",
    "          val_annotations=None,\n",
    "          val_batch_size=2,\n",
    "          auto_resume_checkpoint=False,\n",
    "          load_weights=None,\n",
    "          steps_per_epoch=512,\n",
    "          val_steps_per_epoch=512,\n",
    "          gen_use_multiprocessing=False,\n",
    "          ignore_zero_class=False,\n",
    "          optimizer_name='adam',\n",
    "          do_augment=False,\n",
    "          augmentation_name=\"aug_all\",\n",
    "          callbacks=None,\n",
    "          custom_augmentation=None,\n",
    "          other_inputs_paths=None,\n",
    "          preprocessing=None,\n",
    "          read_image_type=1  # cv2.IMREAD_COLOR = 1 (rgb),\n",
    "                             # cv2.IMREAD_GRAYSCALE = 0,\n",
    "                             # cv2.IMREAD_UNCHANGED = -1 (4 channels like RGBA)\n",
    "         ):\n",
    "    #from .models.all_models import model_from_name\n",
    "    model_from_name = {}\n",
    "    model_from_name[\"vgg_unet\"] = vgg_unet\n",
    "\n",
    "    # check if user gives model name instead of the model object\n",
    "    if isinstance(model, six.string_types):\n",
    "        # create the model from the name\n",
    "        assert (n_classes is not None), \"Please provide the n_classes\"\n",
    "        if (input_height is not None) and (input_width is not None):\n",
    "            model = model_from_name[model](\n",
    "                n_classes, input_height=input_height, input_width=input_width)\n",
    "        else:\n",
    "            model = model_from_name[model](n_classes)\n",
    "\n",
    "    n_classes = model.n_classes\n",
    "    input_height = model.input_height\n",
    "    input_width = model.input_width\n",
    "    output_height = model.output_height\n",
    "    output_width = model.output_width\n",
    "\n",
    "    if validate:\n",
    "        assert val_images is not None\n",
    "        assert val_annotations is not None\n",
    "\n",
    "    if optimizer_name is not None:\n",
    "\n",
    "        if ignore_zero_class:\n",
    "            loss_k = masked_categorical_crossentropy\n",
    "        else:\n",
    "            loss_k = 'categorical_crossentropy'\n",
    "\n",
    "        model.compile(loss=loss_k,\n",
    "                      optimizer=optimizer_name,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    if checkpoints_path is not None:\n",
    "        config_file = checkpoints_path + \"_config.json\"\n",
    "        dir_name = os.path.dirname(config_file)\n",
    "\n",
    "        if ( not os.path.exists(dir_name) )  and len( dir_name ) > 0 :\n",
    "            os.makedirs(dir_name)\n",
    "\n",
    "        with open(config_file, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"model_class\": model.model_name,\n",
    "                \"n_classes\": n_classes,\n",
    "                \"input_height\": input_height,\n",
    "                \"input_width\": input_width,\n",
    "                \"output_height\": output_height,\n",
    "                \"output_width\": output_width\n",
    "            }, f)\n",
    "\n",
    "    if load_weights is not None and len(load_weights) > 0:\n",
    "        print(\"Loading weights from \", load_weights)\n",
    "        model.load_weights(load_weights)\n",
    "\n",
    "    initial_epoch = 0\n",
    "\n",
    "    if auto_resume_checkpoint and (checkpoints_path is not None):\n",
    "        latest_checkpoint = find_latest_checkpoint(checkpoints_path)\n",
    "        if latest_checkpoint is not None:\n",
    "            print(\"Loading the weights from latest checkpoint \",\n",
    "                  latest_checkpoint)\n",
    "            model.load_weights(latest_checkpoint)\n",
    "\n",
    "            initial_epoch = int(latest_checkpoint.split('.')[-1])\n",
    "\n",
    "    if verify_dataset:\n",
    "        print(\"Verifying training dataset\")\n",
    "        verified = verify_segmentation_dataset(train_images,\n",
    "                                               train_annotations,\n",
    "                                               n_classes)\n",
    "        assert verified\n",
    "        if validate:\n",
    "            print(\"Verifying validation dataset\")\n",
    "            verified = verify_segmentation_dataset(val_images,\n",
    "                                                   val_annotations,\n",
    "                                                   n_classes)\n",
    "            assert verified\n",
    "\n",
    "    train_gen = image_segmentation_generator(\n",
    "        train_images, train_annotations,  batch_size,  n_classes,\n",
    "        input_height, input_width, output_height, output_width,\n",
    "        do_augment=do_augment, augmentation_name=augmentation_name,\n",
    "        custom_augmentation=custom_augmentation, other_inputs_paths=other_inputs_paths,\n",
    "        preprocessing=preprocessing, read_image_type=read_image_type)\n",
    "\n",
    "    if validate:\n",
    "        val_gen = image_segmentation_generator(\n",
    "            val_images, val_annotations,  val_batch_size,\n",
    "            n_classes, input_height, input_width, output_height, output_width,\n",
    "            other_inputs_paths=other_inputs_paths,\n",
    "            preprocessing=preprocessing, read_image_type=read_image_type)\n",
    "\n",
    "    if callbacks is None and (not checkpoints_path is  None) :\n",
    "        default_callback = ModelCheckpoint(\n",
    "                filepath=checkpoints_path + \".{epoch:05d}\",\n",
    "                save_weights_only=True,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "        if sys.version_info[0] < 3: # for pyhton 2 \n",
    "            default_callback = CheckpointsCallback(checkpoints_path)\n",
    "\n",
    "        callbacks = [\n",
    "            default_callback\n",
    "        ]\n",
    "\n",
    "    if callbacks is None:\n",
    "        callbacks = []\n",
    "\n",
    "    if not validate:\n",
    "        model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                  epochs=epochs, callbacks=callbacks, initial_epoch=initial_epoch)\n",
    "    else:\n",
    "        model.fit(train_gen,\n",
    "                  steps_per_epoch=steps_per_epoch,\n",
    "                  validation_data=val_gen,\n",
    "                  validation_steps=val_steps_per_epoch,\n",
    "                  epochs=epochs, callbacks=callbacks,\n",
    "                  use_multiprocessing=gen_use_multiprocessing, initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNqPP8VA1d6h",
    "outputId": "155b44af-a89d-4040-8e67-29246cf6292b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 % 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3Z2yLNn0zEg6"
   },
   "outputs": [],
   "source": [
    "def get_vgg_encoder(input_height=224,  input_width=224, pretrained='imagenet', channels=1):\n",
    "\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(channels, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, channels))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               name='block1_conv1', data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               name='block1_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               name='block2_conv1', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               name='block2_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv1', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               name='block3_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv1', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block4_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv1', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv2', data_format=IMAGE_ORDERING)(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               name='block5_conv3', data_format=IMAGE_ORDERING)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool',\n",
    "                     data_format=IMAGE_ORDERING)(x)\n",
    "    f5 = x\n",
    "\n",
    "    if pretrained == 'imagenet':\n",
    "        VGG_Weights_path = tf.keras.utils.get_file(\n",
    "            pretrained_url.split(\"/\")[-1], pretrained_url)\n",
    "        Model(img_input, x).load_weights(VGG_Weights_path, by_name=True, skip_mismatch=True)\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Bq7toelRz4qS"
   },
   "outputs": [],
   "source": [
    "pretrained_url = \"https://github.com/fchollet/deep-learning-models/\" \\\n",
    "                  \"releases/download/v0.1/\" \\\n",
    "                  \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kmwiMX7n0TqT"
   },
   "outputs": [],
   "source": [
    "def get_segmentation_model(input, output):\n",
    "\n",
    "    img_input = input\n",
    "    o = output\n",
    "\n",
    "    o_shape = Model(img_input, o).output_shape\n",
    "    i_shape = Model(img_input, o).input_shape\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        output_height = o_shape[2]\n",
    "        output_width = o_shape[3]\n",
    "        input_height = i_shape[2]\n",
    "        input_width = i_shape[3]\n",
    "        n_classes = o_shape[1]\n",
    "        o = (Reshape((-1, output_height*output_width)))(o)\n",
    "        o = (Permute((2, 1)))(o)\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        output_height = o_shape[1]\n",
    "        output_width = o_shape[2]\n",
    "        input_height = i_shape[1]\n",
    "        input_width = i_shape[2]\n",
    "        n_classes = o_shape[3]\n",
    "        o = (Reshape((output_height*output_width, -1)))(o)\n",
    "\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model(img_input, o)\n",
    "    model.output_width = output_width\n",
    "    model.output_height = output_height\n",
    "    model.n_classes = n_classes\n",
    "    model.input_height = input_height\n",
    "    model.input_width = input_width\n",
    "    model.model_name = \"\"\n",
    "\n",
    "    model.train = MethodType(train, model)\n",
    "    model.predict_segmentation = MethodType(predict, model)\n",
    "    model.predict_multiple = MethodType(predict_multiple, model)\n",
    "    model.evaluate_segmentation = MethodType(evaluate, model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FI7dfBpU2thD"
   },
   "outputs": [],
   "source": [
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "saygpTpq3H14"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import six\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pFP8VtRl3hdq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from .train import find_latest_checkpoint\n",
    "\n",
    "\n",
    "# from .data_utils.data_loader import get_image_array, get_segmentation_array,\\\n",
    "#     DATA_LOADER_SEED, class_colors, get_pairs_from_paths\n",
    "# from .models.config import IMAGE_ORDERING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JNLYBflw4Woo"
   },
   "outputs": [],
   "source": [
    "DATA_LOADER_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qTpNH45G3bUt"
   },
   "outputs": [],
   "source": [
    "random.seed(DATA_LOADER_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ePtzkeQj4qfH"
   },
   "outputs": [],
   "source": [
    "class_colors = [(random.randint(0, 255), random.randint(\n",
    "    0, 255), random.randint(0, 255)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GXR7lWJA3ZqO"
   },
   "outputs": [],
   "source": [
    "def model_from_checkpoint_path(checkpoints_path):\n",
    "\n",
    "    model_from_name = {}\n",
    "    model_from_name[\"vgg_unet\"] = vgg_unet\n",
    "    \n",
    "    #from .models.all_models import model_from_name\n",
    "    assert (os.path.isfile(checkpoints_path+\"_config.json\")\n",
    "            ), \"Checkpoint not found.\"\n",
    "    model_config = json.loads(\n",
    "        open(checkpoints_path+\"_config.json\", \"r\").read())\n",
    "    latest_weights = find_latest_checkpoint(checkpoints_path)\n",
    "    assert (latest_weights is not None), \"Checkpoint not found.\"\n",
    "    model = model_from_name[model_config['model_class']](\n",
    "        model_config['n_classes'], input_height=model_config['input_height'],\n",
    "        input_width=model_config['input_width'])\n",
    "    print(\"loaded weights \", latest_weights)\n",
    "    status = model.load_weights(latest_weights)\n",
    "\n",
    "    if status is not None:\n",
    "        status.expect_partial()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "APIVFST13YpZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def get_colored_segmentation_image(seg_arr, n_classes, colors=class_colors):\n",
    "#     output_height = seg_arr.shape[0]\n",
    "#     output_width = seg_arr.shape[1]\n",
    "\n",
    "#     seg_img = np.zeros((output_height, output_width, 3))\n",
    "\n",
    "#     for c in range(n_classes):\n",
    "#         seg_arr_c = seg_arr[:, :] == c\n",
    "#         seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n",
    "#         seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n",
    "#         seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n",
    "\n",
    "#     return seg_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iv8LnL9z3Xut"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def get_legends(class_names, colors=class_colors):\n",
    "\n",
    "#     n_classes = len(class_names)\n",
    "#     legend = np.zeros(((len(class_names) * 25) + 25, 125, 3),\n",
    "#                       dtype=\"uint8\") + 255\n",
    "\n",
    "#     class_names_colors = enumerate(zip(class_names[:n_classes],\n",
    "#                                        colors[:n_classes]))\n",
    "\n",
    "#     for (i, (class_name, color)) in class_names_colors:\n",
    "#         color = [int(c) for c in color]\n",
    "#         cv2.putText(legend, class_name, (5, (i * 25) + 17),\n",
    "#                     cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)\n",
    "#         cv2.rectangle(legend, (100, (i * 25)), (125, (i * 25) + 25),\n",
    "#                       tuple(color), -1)\n",
    "\n",
    "#     return legend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgVcwPwO3Vi4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def overlay_seg_image(inp_img, seg_img):\n",
    "#     orininal_h = inp_img.shape[0]\n",
    "#     orininal_w = inp_img.shape[1]\n",
    "#     seg_img = cv2.resize(seg_img, (orininal_w, orininal_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "#     fused_img = (inp_img/2 + seg_img/2).astype('uint8')\n",
    "#     return fused_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCNjhwuD3U1j"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def concat_lenends(seg_img, legend_img):\n",
    "\n",
    "#     new_h = np.maximum(seg_img.shape[0], legend_img.shape[0])\n",
    "#     new_w = seg_img.shape[1] + legend_img.shape[1]\n",
    "\n",
    "#     out_img = np.zeros((new_h, new_w, 3)).astype('uint8') + legend_img[0, 0, 0]\n",
    "\n",
    "#     out_img[:legend_img.shape[0], :  legend_img.shape[1]] = np.copy(legend_img)\n",
    "#     out_img[:seg_img.shape[0], legend_img.shape[1]:] = np.copy(seg_img)\n",
    "\n",
    "#     return out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2pXg1Uu3T6W"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def visualize_segmentation(seg_arr, inp_img=None, n_classes=None,\n",
    "#                            colors=class_colors, class_names=None,\n",
    "#                            overlay_img=False, show_legends=False,\n",
    "#                            prediction_width=None, prediction_height=None):\n",
    "\n",
    "#     if n_classes is None:\n",
    "#         n_classes = np.max(seg_arr)\n",
    "\n",
    "#     seg_img = get_colored_segmentation_image(seg_arr, n_classes, colors=colors)\n",
    "\n",
    "#     if inp_img is not None:\n",
    "#         original_h = inp_img.shape[0]\n",
    "#         original_w = inp_img.shape[1]\n",
    "#         seg_img = cv2.resize(seg_img, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "#     if (prediction_height is not None) and (prediction_width is not None):\n",
    "#         seg_img = cv2.resize(seg_img, (prediction_width, prediction_height), interpolation=cv2.INTER_NEAREST)\n",
    "#         if inp_img is not None:\n",
    "#             inp_img = cv2.resize(inp_img,\n",
    "#                                  (prediction_width, prediction_height))\n",
    "\n",
    "#     if overlay_img:\n",
    "#         assert inp_img is not None\n",
    "#         seg_img = overlay_seg_image(inp_img, seg_img)\n",
    "\n",
    "#     if show_legends:\n",
    "#         assert class_names is not None\n",
    "#         legend_img = get_legends(class_names, colors=colors)\n",
    "\n",
    "#         seg_img = concat_lenends(seg_img, legend_img)\n",
    "\n",
    "#     return seg_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQ3VOOq43Od5"
   },
   "outputs": [],
   "source": [
    "def predict(model=None, inp=None, out_fname=None,\n",
    "            checkpoints_path=None, overlay_img=False,\n",
    "            class_names=None, show_legends=False, colors=class_colors,\n",
    "            prediction_width=None, prediction_height=None,\n",
    "            read_image_type=1):\n",
    "\n",
    "    if model is None and (checkpoints_path is not None):\n",
    "        model = model_from_checkpoint_path(checkpoints_path)\n",
    "\n",
    "    assert (inp is not None)\n",
    "    assert ((type(inp) is np.ndarray) or isinstance(inp, six.string_types)),\\\n",
    "        \"Input should be the CV image or the input file name\"\n",
    "\n",
    "    if isinstance(inp, six.string_types):\n",
    "        inp = cv2.imread(inp, read_image_type)\n",
    "\n",
    "    assert (len(inp.shape) == 3 or len(inp.shape) == 1 or len(inp.shape) == 4), \"Image should be h,w,3 \"\n",
    "\n",
    "    output_width = model.output_width\n",
    "    output_height = model.output_height\n",
    "    input_width = model.input_width\n",
    "    input_height = model.input_height\n",
    "    n_classes = model.n_classes\n",
    "\n",
    "    x = get_image_array(inp, input_width, input_height,\n",
    "                        ordering=IMAGE_ORDERING)\n",
    "    pr = model.predict(np.array([x]))[0]\n",
    "    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n",
    "\n",
    "    seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n",
    "                                     colors=colors, overlay_img=overlay_img,\n",
    "                                     show_legends=show_legends,\n",
    "                                     class_names=class_names,\n",
    "                                     prediction_width=prediction_width,\n",
    "                                     prediction_height=prediction_height)\n",
    "\n",
    "    if out_fname is not None:\n",
    "        cv2.imwrite(out_fname, seg_img)\n",
    "\n",
    "    return pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93j5aEoe3SF9"
   },
   "outputs": [],
   "source": [
    "def predict_multiple(model=None, inps=None, inp_dir=None, out_dir=None,\n",
    "                     checkpoints_path=None, overlay_img=False,\n",
    "                     class_names=None, show_legends=False, colors=class_colors,\n",
    "                     prediction_width=None, prediction_height=None, read_image_type=1):\n",
    "\n",
    "    if model is None and (checkpoints_path is not None):\n",
    "        model = model_from_checkpoint_path(checkpoints_path)\n",
    "\n",
    "    if inps is None and (inp_dir is not None):\n",
    "        inps = glob.glob(os.path.join(inp_dir, \"*.jpg\")) + glob.glob(\n",
    "            os.path.join(inp_dir, \"*.png\")) + \\\n",
    "            glob.glob(os.path.join(inp_dir, \"*.jpeg\"))\n",
    "        inps = sorted(inps)\n",
    "\n",
    "    assert type(inps) is list\n",
    "\n",
    "    all_prs = []\n",
    "\n",
    "    if not out_dir is None:\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "\n",
    "\n",
    "    for i, inp in enumerate(tqdm(inps)):\n",
    "        if out_dir is None:\n",
    "            out_fname = None\n",
    "        else:\n",
    "            if isinstance(inp, six.string_types):\n",
    "                out_fname = os.path.join(out_dir, os.path.basename(inp))\n",
    "            else:\n",
    "                out_fname = os.path.join(out_dir, str(i) + \".jpg\")\n",
    "\n",
    "        pr = predict(model, inp, out_fname,\n",
    "                     overlay_img=overlay_img, class_names=class_names,\n",
    "                     show_legends=show_legends, colors=colors,\n",
    "                     prediction_width=prediction_width,\n",
    "                     prediction_height=prediction_height, read_image_type=read_image_type)\n",
    "\n",
    "        all_prs.append(pr)\n",
    "\n",
    "    return all_prs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K25uO2Ba3RHT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def set_video(inp, video_name):\n",
    "#     cap = cv2.VideoCapture(inp)\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     size = (video_width, video_height)\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "#     video = cv2.VideoWriter(video_name, fourcc, fps, size)\n",
    "#     return cap, video, fps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4q8_PlWn3P-T"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def predict_video(model=None, inp=None, output=None,\n",
    "#                   checkpoints_path=None, display=False, overlay_img=True,\n",
    "#                   class_names=None, show_legends=False, colors=class_colors,\n",
    "#                   prediction_width=None, prediction_height=None):\n",
    "\n",
    "#     if model is None and (checkpoints_path is not None):\n",
    "#         model = model_from_checkpoint_path(checkpoints_path)\n",
    "#     n_classes = model.n_classes\n",
    "\n",
    "#     cap, video, fps = set_video(inp, output)\n",
    "#     while(cap.isOpened()):\n",
    "#         prev_time = time()\n",
    "#         ret, frame = cap.read()\n",
    "#         if frame is not None:\n",
    "#             pr = predict(model=model, inp=frame)\n",
    "#             fused_img = visualize_segmentation(\n",
    "#                 pr, frame, n_classes=n_classes,\n",
    "#                 colors=colors,\n",
    "#                 overlay_img=overlay_img,\n",
    "#                 show_legends=show_legends,\n",
    "#                 class_names=class_names,\n",
    "#                 prediction_width=prediction_width,\n",
    "#                 prediction_height=prediction_height\n",
    "#                 )\n",
    "#         else:\n",
    "#             break\n",
    "#         print(\"FPS: {}\".format(1/(time() - prev_time)))\n",
    "#         if output is not None:\n",
    "#             video.write(fused_img)\n",
    "#         if display:\n",
    "#             cv2.imshow('Frame masked', fused_img)\n",
    "#             if cv2.waitKey(fps) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "#     cap.release()\n",
    "#     if output is not None:\n",
    "#         video.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RypP7Prq3J6w"
   },
   "outputs": [],
   "source": [
    "def evaluate(model=None, inp_images=None, annotations=None,\n",
    "             inp_images_dir=None, annotations_dir=None, checkpoints_path=None, read_image_type=1):\n",
    "\n",
    "    if model is None:\n",
    "        assert (checkpoints_path is not None),\\\n",
    "                \"Please provide the model or the checkpoints_path\"\n",
    "        model = model_from_checkpoint_path(checkpoints_path)\n",
    "\n",
    "    if inp_images is None:\n",
    "        assert (inp_images_dir is not None),\\\n",
    "                \"Please provide inp_images or inp_images_dir\"\n",
    "        assert (annotations_dir is not None),\\\n",
    "            \"Please provide inp_images or inp_images_dir\"\n",
    "\n",
    "        paths = get_pairs_from_paths(inp_images_dir, annotations_dir)\n",
    "        paths = list(zip(*paths))\n",
    "        inp_images = list(paths[0])\n",
    "        annotations = list(paths[1])\n",
    "\n",
    "    assert type(inp_images) is list\n",
    "    assert type(annotations) is list\n",
    "\n",
    "    tp = np.zeros(model.n_classes)\n",
    "    fp = np.zeros(model.n_classes)\n",
    "    fn = np.zeros(model.n_classes)\n",
    "    n_pixels = np.zeros(model.n_classes)\n",
    "\n",
    "    for inp, ann in tqdm(zip(inp_images, annotations)):\n",
    "        pr = predict(model, inp, read_image_type=read_image_type)\n",
    "        gt = get_segmentation_array(ann, model.n_classes,\n",
    "                                    model.output_width, model.output_height,\n",
    "                                    no_reshape=True, read_image_type=read_image_type)\n",
    "        gt = gt.argmax(-1)\n",
    "        pr = pr.flatten()\n",
    "        gt = gt.flatten()\n",
    "\n",
    "        for cl_i in range(model.n_classes):\n",
    "\n",
    "            tp[cl_i] += np.sum((pr == cl_i) * (gt == cl_i))\n",
    "            fp[cl_i] += np.sum((pr == cl_i) * ((gt != cl_i)))\n",
    "            fn[cl_i] += np.sum((pr != cl_i) * ((gt == cl_i)))\n",
    "            n_pixels[cl_i] += np.sum(gt == cl_i)\n",
    "\n",
    "    cl_wise_score = tp / (tp + fp + fn + 0.000000000001)\n",
    "    n_pixels_norm = n_pixels / np.sum(n_pixels)\n",
    "    frequency_weighted_IU = np.sum(cl_wise_score*n_pixels_norm)\n",
    "    mean_IU = np.mean(cl_wise_score)\n",
    "\n",
    "    return {\n",
    "        \"frequency_weighted_IU\": frequency_weighted_IU,\n",
    "        \"mean_IU\": mean_IU,\n",
    "        \"class_wise_IU\": cl_wise_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jk8FS0K69yW2"
   },
   "outputs": [],
   "source": [
    "ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\", \".bmp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOdVvg1uuqMg",
    "outputId": "d0eef568-1cab-48c4-c395-1d54ac3c3139"
   },
   "outputs": [],
   "source": [
    "model = vgg_unet(n_classes=2 ,  input_height=128, input_width=128,\n",
    "                 #, \n",
    "                 channels=1 # Sets the number of input channels\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqQojQfVuqPX",
    "outputId": "6b73e538-2d79-4c2f-a7b5-462930257a14"
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_images =  \"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/TRAIN_SMALL/train/img/\",\n",
    "    train_annotations = \"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/TRAIN_SMALL/train/label-0-1/\",\n",
    "    checkpoints_path = \"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/RESULTS/VGG_UNET/1/\" , epochs=5, \n",
    "    read_image_type=0 ) # Sets how opencv will read the images\n",
    "                       # cv2.IMREAD_COLOR = 1 (rgb),\n",
    "                       # cv2.IMREAD_GRAYSCALE = 0,\n",
    "                       # cv2.IMREAD_UNCHANGED = -1 (4 channels like RGBA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MF6fyBNguqSX",
    "outputId": "3a7d2ac8-b777-4561-9b16-cb097daf883f"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4dT8dZFdWjD",
    "outputId": "977f2a8a-6b1e-45ee-a255-8f1b792d5728"
   },
   "outputs": [],
   "source": [
    "cd '/content/drive/MyDrive/DATA/VGG_UNET/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EHY9BTHAdYXP",
    "outputId": "8b4b35ee-e4fe-42b8-8d9c-d2869c2428c8"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M7fWSKddZvF"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUfR5Ba_dbad"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/DATA/VGG_UNET/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7m6S-oLgdfIH",
    "outputId": "02a02c23-1946-478c-e6aa-0362159f797e"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gd00OgqldgHn",
    "outputId": "b65c1908-4c43-4ee0-c943-0982b84a37f5"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iVupCvnZsye"
   },
   "source": [
    "#  LOAD CHECKPOINT AND PREDICT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge5LO44kuqVT"
   },
   "outputs": [],
   "source": [
    "# python -m keras_segmentation predict \\\n",
    "#  --checkpoints_path=\"path_to_checkpoints\" \\\n",
    "#  --input_path=\"dataset1/images_prepped_test/\" \\\n",
    "#  --output_path=\"path_to_predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW57haSZZ9Vi"
   },
   "outputs": [],
   "source": [
    "checkpoints_path = '/content/drive/MyDrive/DATA/VGG_UNET/1/checkpoint-.00005'\n",
    "# HAD TO MOVE BECAUSE GOOGLE COLAB COULDN\"T DETECT IT HERE\n",
    "#'/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/RESULTS/VGG_UNET/1/checkpoint.00005'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "6311fQEfuqYN",
    "outputId": "61566022-9e1d-4198-e33b-b1e961e8d2ed"
   },
   "outputs": [],
   "source": [
    "model = model_from_checkpoint_path(checkpoints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJYWVfWCuqbR",
    "outputId": "79431260-d239-4a40-b720-f6dbc76de05e"
   },
   "outputs": [],
   "source": [
    "cd '/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/RESULTS/VGG_UNET/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p95Z0qjNuqef",
    "outputId": "476be29b-4850-485c-b9cc-b93271384931"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qP1g-RQ2uqhe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwnlNJAGuqkx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf9g3gdUuqn1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tX6ZNhDruqqz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmBEAmXvuqty"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwOGpxVmuqw1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5ge4BO5uq0A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0OvPwSBuq24"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycRvabewuq43"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1Z7qCUxuq7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ0X5XwyWBoK"
   },
   "outputs": [],
   "source": [
    "#https://github.com/divamgupta/image-segmentation-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSW0PzDQW0ur",
    "outputId": "385ba2b7-1607-46f6-b6a2-83f3ed9c8536"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-segmentation\n",
    "!pip install --upgrade git+https://github.com/divamgupta/image-segmentation-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huvjaj7ZZAVm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SM_FRAMEWORK'] = 'tf.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kQuprgJAjnbH",
    "outputId": "640cebed-ee3d-495c-ba61-e66a62585119"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ef_4FANjoYv",
    "outputId": "90e7f90a-59bb-4335-e98e-7ed83bfe673b"
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUqfwqfPjpu2",
    "outputId": "712e61cd-0b13-4e14-9555-c447d699e815"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aVG6yReWHT3",
    "outputId": "7c6c7c91-4259-4026-e192-572df423463e"
   },
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "\n",
    "model = vgg_unet(n_classes=2 ,  input_height=128, input_width=128,\n",
    "                 #, \n",
    "                 channels=1 # Sets the number of input channels\n",
    "                 )\n",
    "\n",
    "# IMPORTANT NOTE: MUST BE DONE, vgg16.py line 79, (in if pretrained == \"imagenet\")\n",
    "# VGG_Weights_path = tf.keras.utils.get_file, import tf and add tf.keras..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "1kLs94HvXWhC",
    "outputId": "160ae4eb-e505-47e4-b5ba-658603ee65b1"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.train(\n",
    "    train_images =  \"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/TRAIN_SMALL/train/img/\",\n",
    "    train_annotations = \"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/TRAIN_SMALL/train/label-0-1/\",\n",
    "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=5, \n",
    "    read_image_type=0  # Sets how opencv will read the images\n",
    "                       # cv2.IMREAD_COLOR = 1 (rgb),\n",
    "                       # cv2.IMREAD_GRAYSCALE = 0,\n",
    "                       # cv2.IMREAD_UNCHANGED = -1 (4 channels like RGBA)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwAFAZz7nUax"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU_2X7dAn7_x"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBHpYobbn_Zi"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEihHbjnnuz3"
   },
   "outputs": [],
   "source": [
    "img = cv.imread(\"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/TRAIN_SMALL/test/img/d850_2_body_crops_1255.png\",cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QAhL27VofFu",
    "outputId": "d519a728-80c8-477e-caa0-eaee0f35d2e2"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "M_v342fWr9IP",
    "outputId": "920df0e8-8612-48fb-e7d5-0b5903314e43"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1E6bsZW6maHM"
   },
   "outputs": [],
   "source": [
    "numpydata = np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVtc4AGSogWG",
    "outputId": "22ce0d33-7ae8-440c-9c21-fa6d32fb9aed"
   },
   "outputs": [],
   "source": [
    "numpydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2vD_u_tomD6",
    "outputId": "88504134-b60b-4e81-f2bf-90312d62190f"
   },
   "outputs": [],
   "source": [
    "np.array([numpydata]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwgpVMhVpRQc"
   },
   "outputs": [],
   "source": [
    "output_width = model.output_width\n",
    "output_height = model.output_height\n",
    "input_width = model.input_width\n",
    "input_height = model.input_height\n",
    "n_classes = model.n_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGDp7sjGrgfv"
   },
   "outputs": [],
   "source": [
    "IMAGE_ORDERING = \"channels_last\" # channels_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otsh6nvxrmw6"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZq6iHO2pRTb"
   },
   "outputs": [],
   "source": [
    "x = get_image_array(numpydata, input_width, input_height,\n",
    "                        ordering=IMAGE_ORDERING)\n",
    "pr = model.predict(np.array([x]))[0]\n",
    "pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_HKmzZnrq97",
    "outputId": "56882756-52ea-48f7-99f1-0284a569c6a9"
   },
   "outputs": [],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cFir1nprveY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "vu2oaRaUrshc",
    "outputId": "6a2c22d2-d782-4c8a-e5a0-cf80a7179dbd"
   },
   "outputs": [],
   "source": [
    "plt.imshow(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h-Ubz93p-yp"
   },
   "outputs": [],
   "source": [
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, read_image_type)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\":\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.atleast_3d(img)\n",
    "\n",
    "        means = [103.939, 116.779, 123.68]\n",
    "\n",
    "        for i in range(min(img.shape[2], len(means))):\n",
    "            img[:, :, i] -= means[i]\n",
    "\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "tRNQouT4maKw",
    "outputId": "3affd450-881e-4222-e98a-ae08cca956af"
   },
   "outputs": [],
   "source": [
    "# pr = model.predict(np.array([numpydata]))[0].argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "0740o_OqoKXe",
    "outputId": "565c3a38-5df1-4744-d58e-ff43f0267925"
   },
   "outputs": [],
   "source": [
    " pr = pr.reshape((128,128,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEGooIAZsITr",
    "outputId": "a8b26319-99a5-4cac-d879-4c0a0e6362f7"
   },
   "outputs": [],
   "source": [
    "64**2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JeYYOEdWHkQ"
   },
   "outputs": [],
   "source": [
    "# out = model.predict_segmentation(\n",
    "#     inp=\"/content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/TRAIN_SMALL/test/img/d850_2_body_crops_1255.png\",\n",
    "#     out_fname=\"/tmp/out.png\"\n",
    "# )\n",
    "\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2ZIdpmcWUVz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLpNPcQJWUYp",
    "outputId": "071973bc-2dba-40f4-bfbd-b88af33f94b2"
   },
   "outputs": [],
   "source": [
    "np.sqrt(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dazWt-N2WUba"
   },
   "outputs": [],
   "source": [
    "# from keras_segmentation.models.unet import vgg_unet\n",
    "\n",
    "# model = vgg_unet(n_classes=51 ,  input_height=416, input_width=608  )\n",
    "\n",
    "# model.train(\n",
    "#     train_images =  \"dataset1/images_prepped_train/\",\n",
    "#     train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "#     checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=5\n",
    "# )\n",
    "\n",
    "# out = model.predict_segmentation(\n",
    "#     inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "#     out_fname=\"/tmp/out.png\"\n",
    "# )\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(out)\n",
    "\n",
    "# # evaluating the model \n",
    "# print(model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m tf2onnx.convert --saved-model /content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/RESULTS/Resnet50_UNET/ONNX/V5_small_Resnet50UNET.pb --opset 13 --output /content/drive/Shareddrives/MYTIDATA/850_RETRO/V5/RESULTS/Resnet50_UNET/ONNX/V5_small_Resnet50UNET.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "vgg_unet_DEV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
